{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Steps of how homework:\n",
    "1) Use two ways of dealing with missing values in datasets\n",
    " a) drop NA and dtype = object\n",
    " b) label \n",
    "2) Calc MAE b/w two options (a & b) and select the best X\n",
    "3) Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, auc, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load housing price data\n",
    "X = pd.read_csv(\"house_params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of NaN for target column\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()]\n",
    "X.drop(cols_with_missing, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)\n",
    "\n",
    "rndmForest = RandomForestRegressor(n_estimators=10, \n",
    "                                    max_depth=5, min_samples_leaf=20, max_features=0.5, \n",
    "                                    n_jobs=-1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     0.483154\n",
       "24    0.101082\n",
       "14    0.086858\n",
       "17    0.074252\n",
       "5     0.062722\n",
       "23    0.060138\n",
       "10    0.044916\n",
       "11    0.020842\n",
       "7     0.019384\n",
       "2     0.010961\n",
       "6     0.009354\n",
       "21    0.007406\n",
       "1     0.005173\n",
       "12    0.004764\n",
       "22    0.003425\n",
       "25    0.002553\n",
       "4     0.001477\n",
       "15    0.001219\n",
       "33    0.000321\n",
       "8     0.000000\n",
       "9     0.000000\n",
       "16    0.000000\n",
       "13    0.000000\n",
       "32    0.000000\n",
       "18    0.000000\n",
       "19    0.000000\n",
       "20    0.000000\n",
       "26    0.000000\n",
       "27    0.000000\n",
       "28    0.000000\n",
       "29    0.000000\n",
       "30    0.000000\n",
       "31    0.000000\n",
       "0     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1 : Get rid of categorical columns (dtype = 'object') \n",
    "X_train_drop = X_train.select_dtypes(exclude=['object'])\n",
    "X_test_drop = X_test.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Fit model on base data\n",
    "rndmForest.fit(X_train_drop, y_train)\n",
    "\n",
    "# Importance of features\n",
    "imp = pd.Series(rndmForest.feature_importances_)\n",
    "imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE_test =  22186.910387846005\n",
      "MAE_train =  20031.37123257425\n"
     ]
    }
   ],
   "source": [
    "#Do preidictions and get MAE\n",
    "y_predicts_test = rndmForest.predict(X_test_drop)\n",
    "y_predicts_train = rndmForest.predict(X_train_drop)\n",
    "mae1_test = mean_absolute_error(y_test,y_predicts_test)\n",
    "mae1_train = mean_absolute_error(y_train,y_predicts_train)\n",
    "print(\"MAE_test = \", mae1_test)\n",
    "print(\"MAE_train = \", mae1_train)\n",
    "\n",
    "# print('Train:')\n",
    "# show_auc(y_train, y_predicts_train, 'train')\n",
    "         \n",
    "# print('Test:')\n",
    "# show_auc(y_test, y_predicts_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    0.467607\n",
       "23    0.118331\n",
       "33    0.063292\n",
       "20    0.055189\n",
       "34    0.052665\n",
       "12    0.048587\n",
       "14    0.048452\n",
       "26    0.047899\n",
       "18    0.037129\n",
       "15    0.018476\n",
       "3     0.012261\n",
       "21    0.009904\n",
       "31    0.006592\n",
       "13    0.002812\n",
       "1     0.002173\n",
       "19    0.001778\n",
       "32    0.001556\n",
       "36    0.000850\n",
       "11    0.000759\n",
       "8     0.000710\n",
       "28    0.000685\n",
       "24    0.000647\n",
       "16    0.000599\n",
       "0     0.000543\n",
       "27    0.000314\n",
       "17    0.000191\n",
       "2     0.000000\n",
       "7     0.000000\n",
       "9     0.000000\n",
       "4     0.000000\n",
       "5     0.000000\n",
       "6     0.000000\n",
       "45    0.000000\n",
       "44    0.000000\n",
       "25    0.000000\n",
       "29    0.000000\n",
       "30    0.000000\n",
       "35    0.000000\n",
       "37    0.000000\n",
       "38    0.000000\n",
       "39    0.000000\n",
       "40    0.000000\n",
       "41    0.000000\n",
       "42    0.000000\n",
       "43    0.000000\n",
       "22    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2  - Label categorical data\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_test[col])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_test = X_test.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# label encoder \n",
    "label = LabelEncoder() \n",
    "for col in set(good_label_cols):\n",
    "    label_X_train[col] = label.fit_transform(X_train[col])\n",
    "    label_X_test[col] = label.transform(X_test[col])\n",
    "\n",
    "# Fit model    \n",
    "rndmForest.fit(label_X_train, y_train)\n",
    "\n",
    "# Importance of features\n",
    "imp = pd.Series(rndmForest.feature_importances_)\n",
    "imp.sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE2_test =  21209.319955660583\n",
      "MAE2_train =  19390.172332286147\n"
     ]
    }
   ],
   "source": [
    "# Option 2 : Predict\n",
    "y_predicts_test = rndmForest.predict(label_X_test)\n",
    "y_predicts_train = rndmForest.predict(label_X_train)\n",
    "mae2_test = mean_absolute_error(y_test,y_predicts_test)\n",
    "mae2_train = mean_absolute_error(y_train,y_predicts_train)\n",
    "print(\"MAE2_test = \", mae2_test)\n",
    "print(\"MAE2_train = \", mae2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to choose X_train by MAE\n",
    "def X_better(mae1, mae2):\n",
    "    if mae1_test > mae2_test:\n",
    "        print(\"Better Option 2, MAE2_test = {} when MAE1_test = {}, label_X_train\".format(mae2_test, mae1_test))\n",
    "        return label_X_train\n",
    "    else:\n",
    "        print(\"Better Option 1, MAE1_test = {} when MAE2_test = {}, X_train_drop \".format(mae1_test, mae2_test))\n",
    "        return X_train_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better Option 2, MAE2_test = 21209.319955660583 when MAE1_test = 22186.910387846005, label_X_train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingRegressor(estimators=[('lr', LinearRegression()),\n",
       "                              ('svr', SVR(kernel='linear')),\n",
       "                              ('rd', Ridge(random_state=11))],\n",
       "                  final_estimator=SVR(kernel='linear'))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Stacking\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "estimators = [\n",
    "    ('lr', LinearRegression()),\n",
    "    ('svr', SVR(kernel='linear')),\n",
    "    ('rd', Ridge(random_state=11))\n",
    "]\n",
    "\n",
    "final_estimator = SVR(kernel='linear')\n",
    "\n",
    "regressor = StackingRegressor(\n",
    "    estimators=estimators, final_estimator=final_estimator\n",
    ")\n",
    "\n",
    "X_better_train = X_better(mae1_test, mae2_test)\n",
    "\n",
    "regressor.fit(X_better_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': LinearRegression(),\n",
       " 'svr': SVR(kernel='linear'),\n",
       " 'rd': Ridge(random_state=11)}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.named_estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([313568.82022859,  91846.32685091, 124552.72686006, ...,\n",
       "       139101.94097139, 203491.0313492 , 212658.24433138])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_better_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 900731423.6706\n",
      "Variance Score: 0.8537\n"
     ]
    }
   ],
   "source": [
    "# MSE and VS\n",
    "\n",
    "print(\"Mean Squared Error: %.4f\"\n",
    "      % np.mean((regressor.predict(X_better_train) - y_train) ** 2))\n",
    "print('Variance Score: %.4f' % regressor.score(X_better_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xcfd0126ef0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(regressor.final_estimator_.coef_.flatten(), index=regressor.named_estimators_.keys()).plot(kind='barh')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
